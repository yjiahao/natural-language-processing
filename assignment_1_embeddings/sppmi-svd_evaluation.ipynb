{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f597a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16a4013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_co_matrix(vocab: dict, window_size: int, tokenized_sentences: list):\n",
    "    vocab_size = len(vocab)\n",
    "    co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.float32)\n",
    "\n",
    "    for sentence in tokenized_sentences:\n",
    "        sentence_length = len(sentence)\n",
    "        for idx, word in enumerate(sentence):\n",
    "            word_idx = vocab[word]\n",
    "            \n",
    "            # Define the context window\n",
    "            start = max(0, idx - window_size)\n",
    "            end = min(sentence_length, idx + window_size + 1)\n",
    "            \n",
    "            # Update co-occurrence counts for words in the window\n",
    "            for context_idx in range(start, end):\n",
    "                if idx != context_idx:  # Skip the word itself\n",
    "                    context_word_idx = vocab[sentence[context_idx]]\n",
    "                    co_matrix[word_idx, context_word_idx] += 1\n",
    "\n",
    "    return co_matrix\n",
    "\n",
    "def create_sppmi_matrix(co_matrix, co_occurrence_sum, word_occurrences, k):\n",
    "    sppmi_matrix = np.zeros_like(co_matrix)\n",
    "    \n",
    "    # Find indices where co_matrix > 0\n",
    "    rows, cols = np.nonzero(co_matrix)\n",
    "\n",
    "    for i, j in zip(rows, cols):\n",
    "        pmi = np.log((co_matrix[i, j] * co_occurrence_sum) / (word_occurrences[i] * word_occurrences[j]))\n",
    "        sppmi = pmi - np.log(k)\n",
    "        sppmi_matrix[i, j] = max(sppmi, 0)  # SPPMI\n",
    "\n",
    "    return sppmi_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e0bab50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting SVD model with dimensions = 128, window size = 5, k = 5\n"
     ]
    }
   ],
   "source": [
    "# load data and get sppmi embeddings again using best SVD model found previously\n",
    "df = pd.read_csv('../data/evaluation/wordsim353crowd.csv')\n",
    "twitter = pd.read_csv('../data/twitter/processed.csv')\n",
    "\n",
    "twitter['processed_text'] = twitter['processed_text'].apply(lambda x: ast.literal_eval(x))\n",
    "tokenized_sentences = list(twitter['processed_text'])\n",
    "\n",
    "vocab = {\n",
    "    word: idx for idx, word in enumerate(set(word for sentence in tokenized_sentences for word in sentence))\n",
    "}\n",
    "\n",
    "co_matrix = create_co_matrix(vocab, 5, tokenized_sentences)\n",
    "co_occurrence_sum = np.sum(co_matrix)\n",
    "word_occurrences = np.sum(co_matrix, axis=1)\n",
    "\n",
    "# create sppmi matrix\n",
    "sppmi_matrix = create_sppmi_matrix(co_matrix, co_occurrence_sum, word_occurrences, 5)\n",
    "\n",
    "# fit svd\n",
    "print(f'Fitting SVD model with dimensions = {128}, window size = {5}, k = {5}')\n",
    "\n",
    "svd = TruncatedSVD(n_components=128)\n",
    "U_k = svd.fit_transform(sppmi_matrix)\n",
    "Sigma_k = np.diag(svd.singular_values_)\n",
    "Sigma_k_sqrt = np.sqrt(Sigma_k)\n",
    "sppmi_embedding = U_k @ Sigma_k_sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "016824fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = vocab\n",
    "index_to_word = {idx: word for word, idx in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c22fe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    w1, w2 = row['Word 1'], row['Word 2']\n",
    "    if w1 in word_to_index and w2 in word_to_index:\n",
    "        vec1 = sppmi_embedding[word_to_index[w1]].reshape(1, -1)\n",
    "        vec2 = sppmi_embedding[word_to_index[w2]].reshape(1, -1)\n",
    "        sim = cosine_similarity(vec1, vec2)[0][0]\n",
    "        preds.append(sim)\n",
    "    else:\n",
    "        preds.append(np.nan) # result not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17f1591d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['preds'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa5c6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna() # remove the words that are not part of our vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7637b682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation: 0.07769054899203413\n",
      "Pearson correlation: 0.15669632206080575\n"
     ]
    }
   ],
   "source": [
    "print(\"Spearman correlation:\", spearmanr(df['preds'], df['Human (Mean)'])[0])\n",
    "print(\"Pearson correlation:\", pearsonr(df['preds'], df['Human (Mean)'])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a53992",
   "metadata": {},
   "source": [
    "We can see that there is low correlation between the similarity scores from the SPPMI-SVD vectors and the human scores, indicating poor performance of the model.\n",
    "\n",
    "This is expected as the 10k tweets we used probably did not contain enough data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "natural-language-processing-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
