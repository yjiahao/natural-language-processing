---
title: "glove sentiment analysis"
author: "Jia Hao"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Import libraries

```{r}
library(text2vec)
library(readr)
library(stringr)
library(ggplot2)
library(dplyr)
library(randomForest)
```

## Read data and preprocess it

```{r}
df_train = read.csv(
  '../data/twitter/train_processed.csv',
  header=TRUE,
  encoding='latin-1'
)

# Remove square brackets and quotes
df_train$processed_text <- str_remove_all(df_train$processed_text, "\\[|\\]|'")

# Split by comma or space
df_train$processed_text <- str_split(df_train$processed_text, ",\\s*")

tokenized_sentences_train = df_train$processed_text

# Create an iterator over the tokens
it <- itoken(tokenized_sentences_train, progressbar = TRUE)

# Build the vocabulary
vocab <- create_vocabulary(it)

# fit glove model
window = 5
rank = 256

tcm <- create_tcm(it, vectorizer = vocab_vectorizer(vocab), skip_grams_window = window)

# Define the GloVe model
glove <- GlobalVectors$new(rank = rank, x_max = 10)  # rank = embedding dimensions

print(paste("Window length: ", window, ", Vector dimensions: ", rank))

# Fit the GloVe model
word_vectors <- glove$fit_transform(tcm, n_iter = 10, convergence_tol = 0.01)

# Combine word and context embeddings (optional)
word_vectors <- word_vectors + t(glove$components)
```
```{r}
df_test = read.csv(
  '../data/twitter/test_processed.csv',
  header=TRUE,
  encoding='latin-1'
)

# Remove square brackets and quotes
df_test$processed_text <- str_remove_all(df_test$processed_text, "\\[|\\]|'")

# Split by comma or space
df_test$processed_text <- str_split(df_test$processed_text, ",\\s*")

tokenized_sentences_test = df_test$processed_text
```

## Embed sentences

```{r}
sentence_embedding <- function(tokens, embeddings) {
  tokens <- tokens[tokens %in% rownames(embeddings)]  # keep only in-vocab words
  if (length(tokens) == 0) {
    return(rep(0, ncol(embeddings)))  # return zero vector if all OOV
  }
  vecs <- embeddings[tokens, , drop = FALSE]
  colMeans(vecs)  # average across words
}

sentence_embeddings_train <- lapply(tokenized_sentences_train, sentence_embedding, embeddings = word_vectors)
X_train <- do.call(rbind, sentence_embeddings_train)

sentence_embeddings_test <- lapply(tokenized_sentences_test, sentence_embedding, embeddings = word_vectors)
X_test <- do.call(rbind, sentence_embeddings_test)

y_train <- df_train$target
y_test <- df_test$target
```

## Train random forest model

```{r}
set.seed(42)
rf_model <- randomForest(
  x = X_train,
  y = as.factor(y_train),
  n_tree = 200
)
```

```{r}
y_pred <- predict(rf_model, newdata = X_test)

confusion <- table(Predicted = y_pred, Actual = y_test)
print(confusion)
cat("\n")

accuracy <- sum(y_pred == y_test) / length(y_test)
cat("Test Accuracy:", accuracy, "\n")
```

## Train logistic regression model

```{r}
set.seed(42)
y_train = as.factor(y_train)
y_test = as.factor(y_test)

logreg_model = glm(y_train ~ .,
                   data = data.frame(y_train = y_train, X_train),
                   family = binomial)
```

```{r}
pred_probs <- predict(logreg_model, newdata = data.frame(X_test), type = "response")

# Convert to class labels (threshold = 0.5 by default)
y_pred <- ifelse(pred_probs > 0.5, levels(y_train)[2], levels(y_train)[1])
y_pred <- factor(y_pred, levels = levels(y_train))

confusion <- table(Predicted = y_pred, Actual = y_test)
print(confusion)
cat("\n")

accuracy <- sum(y_pred == y_test) / length(y_test)
cat("Test Accuracy:", accuracy, "\n")
```

Random Forest performs slightly better than the Logistic Regression model for sentiment analysis with GloVe.